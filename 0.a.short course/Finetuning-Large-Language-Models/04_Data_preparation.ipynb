{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Prompt to get the following codes:\n",
        "Provide Python code for data preparation for fine-tuning a language model. The code should include loading a dataset in JSONL format, tokenizing text using Hugging Faceâ€™s tokenizer, applying padding and truncation, and preparing the data for training by creating a question-answer format. It should also show how to split the dataset into train and test sets and print a sample of tokenized inputs."
      ],
      "metadata": {
        "id": "OUohlaCBtlMs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-NxmfuOT5yB"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 98,
        "id": "qSEqgeA468du"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "\n",
        "from pprint import pprint\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "iE5rEocMmkW6"
      },
      "source": [
        "### Tokenizing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "colab": {
          "referenced_widgets": [
            "26b485d6f86b4916a68dc8681266646e",
            "374fcc4a03fa41d4b6fcd825ad64c715",
            "4702c78f481b4968b62ebd720e983edb"
          ]
        },
        "id": "sAkxl0ljmkW7",
        "outputId": "307c77e6-3b8e-43c6-d59e-8efde14be05b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26b485d6f86b4916a68dc8681266646e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "374fcc4a03fa41d4b6fcd825ad64c715",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4702c78f481b4968b62ebd720e983edb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "vl1HGX5xmkW9"
      },
      "outputs": [],
      "source": [
        "text = \"Hi, how are you?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "LBlIdWVLmkW-"
      },
      "outputs": [],
      "source": [
        "encoded_text = tokenizer(text)[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "qpcMMci8mkW_",
        "outputId": "deaadb34-e2bb-450c-c6ad-46468d5c45d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[12764, 13, 849, 403, 368, 32]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "GerxfIuZmkXA",
        "outputId": "092c00f2-9ceb-4107-f63e-bdff839adecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoded tokens back into text:  Hi, how are you?\n"
          ]
        }
      ],
      "source": [
        "decoded_text = tokenizer.decode(encoded_text)\n",
        "print(\"Decoded tokens back into text: \", decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv1H0IxxmkXB"
      },
      "source": [
        "### Tokenize multiple texts at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "7BOYd9rYmkXC",
        "outputId": "f38902db-9e42-45ed-d9c2-6d40423b55ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded several texts:  [[12764, 13, 849, 403, 368, 32], [42, 1353, 1175], [4374]]\n"
          ]
        }
      ],
      "source": [
        "list_texts = [\"Hi, how are you?\", \"I'm good\", \"Yes\"]\n",
        "encoded_texts = tokenizer(list_texts)\n",
        "print(\"Encoded several texts: \", encoded_texts[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiUT3ANUmkXE"
      },
      "source": [
        "### Padding and truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "nX1-Ul92mkXE",
        "outputId": "fea84ec9-5eb5-4415-f5c2-8fc91f08bb08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using padding:  [[12764, 13, 849, 403, 368, 32], [42, 1353, 1175, 0, 0, 0], [4374, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "encoded_texts_longest = tokenizer(list_texts, padding=True)\n",
        "print(\"Using padding: \", encoded_texts_longest[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "5T2OBUnTmkXF",
        "outputId": "7b44748d-3547-4973-bd14-75e4fee23d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using truncation:  [[12764, 13, 849], [42, 1353, 1175], [4374]]\n"
          ]
        }
      ],
      "source": [
        "encoded_texts_truncation = tokenizer(list_texts, max_length=3, truncation=True)\n",
        "print(\"Using truncation: \", encoded_texts_truncation[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "4NPcGlTumkXG",
        "outputId": "75c11003-b899-43e8-f73e-47fceb04ae87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using left-side truncation:  [[403, 368, 32], [42, 1353, 1175], [4374]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer.truncation_side = \"left\"\n",
        "encoded_texts_truncation_left = tokenizer(list_texts, max_length=3, truncation=True)\n",
        "print(\"Using left-side truncation: \", encoded_texts_truncation_left[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "GoNtYc00mkXI",
        "outputId": "cee58774-d6f2-42f5-8603-841b5b7e8f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using both padding and truncation:  [[403, 368, 32], [42, 1353, 1175], [4374, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "encoded_texts_both = tokenizer(list_texts, max_length=3, truncation=True, padding=True)\n",
        "print(\"Using both padding and truncation: \", encoded_texts_both[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OZYPHeJmkXJ"
      },
      "source": [
        "### Prepare instruction dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 540,
        "id": "qOWO7xHnmkXK",
        "outputId": "5d3a2750-d4a6-4169-a89a-54d907c8452d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One datapoint in the finetuning dataset:\n",
            "{'answer': 'Lamini has documentation on Getting Started, Authentication, '\n",
            "           'Question Answer Model, Python Library, Batching, Error Handling, '\n",
            "           'Advanced topics, and class documentation on LLM Engine available '\n",
            "           'at https://lamini-ai.github.io/.',\n",
            " 'question': '### Question:\\n'\n",
            "             'What are the different types of documents available in the '\n",
            "             'repository (e.g., installation guide, API documentation, '\n",
            "             \"developer's guide)?\\n\"\n",
            "             '\\n'\n",
            "             '### Answer:'}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = \"lamini_docs.jsonl\"\n",
        "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
        "examples = instruction_dataset_df.to_dict()\n",
        "\n",
        "if \"question\" in examples and \"answer\" in examples:\n",
        "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "elif \"instruction\" in examples and \"response\" in examples:\n",
        "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
        "elif \"input\" in examples and \"output\" in examples:\n",
        "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "else:\n",
        "  text = examples[\"text\"][0]\n",
        "\n",
        "prompt_template = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\"\"\"\n",
        "\n",
        "num_examples = len(examples[\"question\"])\n",
        "finetuning_dataset = []\n",
        "for i in range(num_examples):\n",
        "  question = examples[\"question\"][i]\n",
        "  answer = examples[\"answer\"][i]\n",
        "  text_with_prompt_template = prompt_template.format(question=question)\n",
        "  finetuning_dataset.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
        "\n",
        "from pprint import pprint\n",
        "print(\"One datapoint in the finetuning dataset:\")\n",
        "pprint(finetuning_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzF47j0dmkXL"
      },
      "source": [
        "### Tokenize a single example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 132,
        "id": "X48RUYqCmkXL",
        "outputId": "b404d2b2-cd6c-4b59-ab10-5c72e9bece0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 4118 19782    27   187  1276   403   253  1027  3510   273  7177  2130\n",
            "    275   253 18491   313    70    15    72   904 12692  7102    13  8990\n",
            "  10097    13 13722   434  7102  6177   187   187  4118 37741    27    45\n",
            "   4988    74   556 10097   327 27669 11075   264    13  5271 23058    13\n",
            "  19782 37741 10031    13 13814 11397    13   378 16464    13 11759 10535\n",
            "   1981    13 21798 12989    13   285   966 10097   327 21708    46 10797\n",
            "   2130   387  5987  1358    77  4988    74    14  2284    15  7280    15\n",
            "    900 14206]]\n"
          ]
        }
      ],
      "source": [
        "text = finetuning_dataset[0][\"question\"] + finetuning_dataset[0][\"answer\"]\n",
        "tokenized_inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"np\",\n",
        "    padding=True\n",
        ")\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 98,
        "id": "FwSXKjIjmkXM"
      },
      "outputs": [],
      "source": [
        "max_length = 2048\n",
        "max_length = min(\n",
        "    tokenized_inputs[\"input_ids\"].shape[1],\n",
        "    max_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 115,
        "id": "vWIoaFuImkXN"
      },
      "outputs": [],
      "source": [
        "tokenized_inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"np\",\n",
        "    truncation=True,\n",
        "    max_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "Ce8grTN5mkXO",
        "outputId": "dcf028e6-342d-4041-d54a-f4f27381177d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 4118, 19782,    27,   187,  1276,   403,   253,  1027,  3510,\n",
              "          273,  7177,  2130,   275,   253, 18491,   313,    70,    15,\n",
              "           72,   904, 12692,  7102,    13,  8990, 10097,    13, 13722,\n",
              "          434,  7102,  6177,   187,   187,  4118, 37741,    27,    45,\n",
              "         4988,    74,   556, 10097,   327, 27669, 11075,   264,    13,\n",
              "         5271, 23058,    13, 19782, 37741, 10031,    13, 13814, 11397,\n",
              "           13,   378, 16464,    13, 11759, 10535,  1981,    13, 21798,\n",
              "        12989,    13,   285,   966, 10097,   327, 21708,    46, 10797,\n",
              "         2130,   387,  5987,  1358,    77,  4988,    74,    14,  2284,\n",
              "           15,  7280,    15,   900, 14206]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_inputs[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "385o_nNZmkXO"
      },
      "source": [
        "### Tokenize the instruction dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 489,
        "id": "N--wyKY6mkXP"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    if \"question\" in examples and \"answer\" in examples:\n",
        "      text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "    elif \"input\" in examples and \"output\" in examples:\n",
        "      text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "    else:\n",
        "      text = examples[\"text\"][0]\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        padding=True,\n",
        "    )\n",
        "\n",
        "    max_length = min(\n",
        "        tokenized_inputs[\"input_ids\"].shape[1],\n",
        "        2048\n",
        "    )\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 183,
        "colab": {
          "referenced_widgets": [
            "96cf3adcf9d84a13b28e03d4927426e6",
            "7a43fe8589e34fbca929611d9b2c4e93",
            "14720ed7855b44e68e445ac6694bb91a",
            "a5bb83d7f841445799286ee6b5529a15"
          ]
        },
        "id": "SYBx9a7emkXP",
        "outputId": "b3af3e77-339f-4657-a4c5-0dd19a075fbf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96cf3adcf9d84a13b28e03d4927426e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a43fe8589e34fbca929611d9b2c4e93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14720ed7855b44e68e445ac6694bb91a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5bb83d7f841445799286ee6b5529a15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 1400\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=filename, split=\"train\")\n",
        "\n",
        "tokenized_dataset = finetuning_dataset_loaded.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        "    drop_last_batch=True\n",
        ")\n",
        "\n",
        "print(tokenized_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "YiJdilEDmkXQ",
        "outputId": "f14c3f38-a9a6-4495-ee8d-efca70daf345"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n"
          ]
        }
      ],
      "source": [
        "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_8A_x6qmkXQ"
      },
      "source": [
        "### Prepare test/train splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "yqcBo84fmkXQ",
        "outputId": "77a52d78-dd41-4ba3-85eb-e33211544bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 1260\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 140\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
        "print(split_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zCIUBEVmkXR"
      },
      "source": [
        "### Some datasets for you to try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "colab": {
          "referenced_widgets": [
            "9582b745389741f79258b719440b653b",
            "8332dba1771b43c695d6f0f045c22c2a",
            "d85ae8ce0b9d47cfaa6d11c7cccdab89",
            "d73dcf576d0a44a7983912797aab3b9c",
            "80df3dc205154ad4a294de606450a5e0",
            "214059a5c3334e7ebb6cd33bd2edc868",
            "dede5ea4e45f4aa3974cebb41fa3795d"
          ]
        },
        "id": "KES22ITGmkXR",
        "outputId": "9b9542dc-cdf6-48b6-adf0-d8a2b06aef8e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9582b745389741f79258b719440b653b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/577 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8332dba1771b43c695d6f0f045c22c2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d85ae8ce0b9d47cfaa6d11c7cccdab89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/615k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d73dcf576d0a44a7983912797aab3b9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/83.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80df3dc205154ad4a294de606450a5e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "214059a5c3334e7ebb6cd33bd2edc868",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1260 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dede5ea4e45f4aa3974cebb41fa3795d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/140 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 1260\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 140\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "finetuning_dataset_path = \"lamini/lamini_docs\"\n",
        "finetuning_dataset = datasets.load_dataset(finetuning_dataset_path)\n",
        "print(finetuning_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "7B2B3S9OmkXR"
      },
      "outputs": [],
      "source": [
        "taylor_swift_dataset = \"lamini/taylor_swift\"\n",
        "bts_dataset = \"lamini/bts\"\n",
        "open_llms = \"lamini/open_llms\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "colab": {
          "referenced_widgets": [
            "15521e7d1f9c4056a67d1158bf1e4982",
            "a737302582b047409af567e10cbcd346",
            "cc977f2af7134fdf952bf67ff7290e85",
            "6f413abdfd444caf9bf6d815e63e29ed",
            "85f58154bd884b78a853ee2ad2772238",
            "d79ca254173d42e495c8a4021fac8eeb",
            "5428437d1a7a42b6b289c9584c12cdeb"
          ]
        },
        "id": "SauEiuMMmkXS",
        "outputId": "fa1bb287-a569-4aae-8eb3-53f7643bee10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15521e7d1f9c4056a67d1158bf1e4982",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/573 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a737302582b047409af567e10cbcd346",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc977f2af7134fdf952bf67ff7290e85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/257k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f413abdfd444caf9bf6d815e63e29ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/46.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85f58154bd884b78a853ee2ad2772238",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d79ca254173d42e495c8a4021fac8eeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/783 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5428437d1a7a42b6b289c9584c12cdeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/87 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'What is the most popular Taylor Swift song among millennials? How does this song relate to the millennial generation? What is the significance of this song in the millennial culture?', 'answer': 'Taylor Swift\\'s \"Shake It Off\" is the most popular song among millennials. This song relates to the millennial generation as it is an anthem of self-acceptance and embracing one\\'s individuality. The song\\'s message of not letting others bring you down and to just dance it off resonates with the millennial culture, which is often characterized by a strong sense of individuality and a rejection of societal norms. Additionally, the song\\'s upbeat and catchy melody makes it a perfect fit for the millennial generation, which is known for its love of pop music.', 'input_ids': [1276, 310, 253, 954, 4633, 11276, 24619, 4498, 2190, 24933, 8075, 32, 1359, 1057, 436, 4498, 14588, 281, 253, 24933, 451, 5978, 32, 1737, 310, 253, 8453, 273, 436, 4498, 275, 253, 24933, 451, 4466, 32, 37979, 24619, 434, 346, 2809, 640, 733, 5566, 3, 310, 253, 954, 4633, 4498, 2190, 24933, 8075, 15, 831, 4498, 7033, 281, 253, 24933, 451, 5978, 347, 352, 310, 271, 49689, 273, 1881, 14, 14764, 593, 285, 41859, 581, 434, 2060, 414, 15, 380, 4498, 434, 3935, 273, 417, 13872, 2571, 3324, 368, 1066, 285, 281, 816, 11012, 352, 745, 8146, 684, 342, 253, 24933, 451, 4466, 13, 534, 310, 2223, 7943, 407, 247, 2266, 3282, 273, 2060, 414, 285, 247, 18235, 273, 38058, 22429, 15, 9157, 13, 253, 4498, 434, 598, 19505, 285, 5834, 90, 40641, 2789, 352, 247, 3962, 4944, 323, 253, 24933, 451, 5978, 13, 534, 310, 1929, 323, 697, 2389, 273, 1684, 3440, 15], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1276, 310, 253, 954, 4633, 11276, 24619, 4498, 2190, 24933, 8075, 32, 1359, 1057, 436, 4498, 14588, 281, 253, 24933, 451, 5978, 32, 1737, 310, 253, 8453, 273, 436, 4498, 275, 253, 24933, 451, 4466, 32, 37979, 24619, 434, 346, 2809, 640, 733, 5566, 3, 310, 253, 954, 4633, 4498, 2190, 24933, 8075, 15, 831, 4498, 7033, 281, 253, 24933, 451, 5978, 347, 352, 310, 271, 49689, 273, 1881, 14, 14764, 593, 285, 41859, 581, 434, 2060, 414, 15, 380, 4498, 434, 3935, 273, 417, 13872, 2571, 3324, 368, 1066, 285, 281, 816, 11012, 352, 745, 8146, 684, 342, 253, 24933, 451, 4466, 13, 534, 310, 2223, 7943, 407, 247, 2266, 3282, 273, 2060, 414, 285, 247, 18235, 273, 38058, 22429, 15, 9157, 13, 253, 4498, 434, 598, 19505, 285, 5834, 90, 40641, 2789, 352, 247, 3962, 4944, 323, 253, 24933, 451, 5978, 13, 534, 310, 1929, 323, 697, 2389, 273, 1684, 3440, 15]}\n"
          ]
        }
      ],
      "source": [
        "dataset_swiftie = datasets.load_dataset(taylor_swift_dataset)\n",
        "print(dataset_swiftie[\"train\"][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "N5jQayVfSOP0"
      },
      "outputs": [],
      "source": [
        "# This is how to push your own dataset to your Huggingface hub\n",
        "# !pip install huggingface_hub\n",
        "# !huggingface-cli login\n",
        "# split_dataset.push_to_hub(dataset_path_hf)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}