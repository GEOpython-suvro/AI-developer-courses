Fine tuning full layers , final layers, with adapters:

•Library installation-
 !pip install --upgrade portalocker==2.8.2 torchtext==0.17.0 torchdata==0.7.1 pandas==2.2.2 matplotlib==3.9.0 scikit-learn==1.5.0 torch==2.2.0 numpy==1.23.2

•Imports-
from tqdm import tqdm
import time
import numpy as np
import pandas as pd
from itertools import accumulate
import matplotlib.pyplot as plt
import math
import torch
torch.set_num_threads(1)
from torch import nn
import os
from torch.utils.data import DataLoader, Dataset
from torch.utils.data.dataset import random_split

from torchtext.datasets import AG_NEWS, IMDB
from torchtext.data.utils import get_tokenizer
from torchtext.vocab import build_vocab_from_iterator, GloVe, Vectors
from torchtext.data.functional import to_map_style_dataset

from IPython.display import Markdown as md
import pickle
from urllib.request import urlopen
import io
import tarfile
import tempfile
from torch.nn.utils.rnn import pad_sequence
# You can also use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')

