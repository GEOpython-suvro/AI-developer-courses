{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Adapters in PyTorch**\n",
    "\n",
    "Estimated time needed: **45** minutes\n",
    "\n",
    "**_Note to advanced users_: If you are already familiar with classical fine-tuning and you only want to see the section that relates to adapters, skip forward to <a href=\"#Adapters\">Adapters</a> and run all of the cells above that section by going to _Run --> Run All Above Selected Cell_**\n",
    "\n",
    "You can fine-tune a neural network in several ways. Common strategies include adjusting only the final layer or fine-tuning all layers. However, these methods have their drawbacks: fine-tuning just the final layer often leads to less than optimal results, while fine-tuning all layers can be very time-consuming.\n",
    "\n",
    "To address these issues, researchers have developed various parameter efficient fine-tuning (PEFT) techniques. One such technique involves the use of adapters. Adapters enable modular training, where small, task-specific modules are trained within the model without changing the pre-existing pretrained parameters. This approach efficiently tailors the model to new tasks with a reduced risk of overfitting. However, adapters are not a cure-all solution. While they are less likely to overfit and are computationally efficient, they might not always reach the same level of accuracy as full model fine-tuning, particularly if the task necessitates substantial changes from the pretrained model's original capabilities.\n",
    "\n",
    "In this hands-on lab, you learn how to apply an adapter to a transformer-based neural network that has been trained on the AG News data set, with the aim of using this model on the IMDB data set. You also evaluate and compare the performance of this method with that of a fully fine-tuned model and a model where only the last layer is fine-tuned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Table of contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Install-required-libraries\">Install required libraries</a></li>\n",
    "            <li><a href=\"#Import-required-libraries\">Import required libraries</a></li>\n",
    "            <li><a href=\"#Define-helper-functions\">Defining helper functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Positional-encodings\">Positional encodings</a></li>\n",
    "    <li><a href=\"#Import-IMDB-dataset\">Import IMDB data set</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#IMDB-dataset-overview\">IMDB data set overview</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#Dataset-composition\">Data set composition</a></li>\n",
    "            <li><a href=\"#Applications\">Applications</a></li>\n",
    "            <li><a href=\"#Challenges\">Challenges</a></li>\n",
    "            <li><a href=\"#Dataset-splits\">Data set splits</a></li>\n",
    "            <li><a href=\"#Data-loader\">Data loader</a></li>\n",
    "            <li><a href=\"#Neural-network\">Neural network</a></li>\n",
    "        </ol>\n",
    "    </ol>\n",
    "    <li>\n",
    "        <a href=\"#Training\">Training</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Train-IMDB\">Train IMDB</a></li>\n",
    "            <li><a href=\"#Fine-tune-a-model-pretrained-on-the-AG-News-dataset\">Fine-tune a model pretrained on the AG News data set</a></li>\n",
    "            <li><a href=\"#Fine-tune-the-final-layer-only\">Fine-tune the final layer only</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Adapters\">Adapters</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Benefits-of-using-adapters-in-neural-networks\">Benefits of using adapters in neural networks</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Exercise:-Adapt-linear-layers-in-a-different-network\">Exercise: Adapt linear layers in a different network</a>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "After completing this lab, you are able to:\n",
    "\n",
    "- Define and pretrain a transformer-based neural network using PyTorch for a classification task [Optional]\n",
    "- Fully fine-tune the pretrained model for a different classification task [Optional]\n",
    "- Compare results by fine-tuning only the last layer of the pretrained model [Optional]\n",
    "- Understand how adapters work\n",
    "- Apply adapters to linear layers in a neural network\n",
    "- Train a neural network in a parameter efficient way by training just the adapted layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, you use the following libraries, which are __not__ preinstalled in the Skills Network Labs environment. __You must run the code in the following cell__ to install them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: portalocker==2.8.2 in /opt/conda/lib/python3.11/site-packages (2.8.2)\n",
      "Collecting torchtext==0.17.0\n",
      "  Using cached torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting torchdata==0.7.1\n",
      "  Using cached torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas==2.2.2 in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib==3.9.0 in /opt/conda/lib/python3.11/site-packages (3.9.0)\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /opt/conda/lib/python3.11/site-packages (1.5.0)\n",
      "Collecting torch==2.2.0\n",
      "  Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting numpy==1.23.2\n",
      "  Downloading numpy-1.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from torchtext==0.17.0) (4.66.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from torchtext==0.17.0) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.11/site-packages (from torchdata==0.7.1) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.9.0) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.0) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.0) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch==2.2.0)\n",
      "  Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.6.77)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.6.0 (from scikit-learn==1.5.0)\n",
      "  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->torchtext==0.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->torchtext==0.17.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->torchtext==0.17.0) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.2.0) (1.3.0)\n",
      "Using cached torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "Using cached torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
      "Downloading numpy-1.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, numpy, scipy, torch, torchdata, torchtext\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "  Attempting uninstall: torchdata\n",
      "    Found existing installation: torchdata 0.6.1\n",
      "    Uninstalling torchdata-0.6.1:\n",
      "      Successfully uninstalled torchdata-0.6.1\n",
      "  Attempting uninstall: torchtext\n",
      "\u001b[33m    WARNING: Skipping /opt/conda/lib/python3.11/site-packages/torch-2.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: torchtext 0.15.2\n",
      "    Uninstalling torchtext-0.15.2:\n",
      "      Successfully uninstalled torchtext-0.15.2\n",
      "\u001b[33mWARNING: Skipping /opt/conda/lib/python3.11/site-packages/torch-2.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/conda/lib/python3.11/site-packages/torch-2.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/conda/lib/python3.11/site-packages/torch-2.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/conda/lib/python3.11/site-packages/torch-2.0.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.2 scipy-1.13.1 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade portalocker==2.8.2 torchtext==0.17.0 torchdata==0.7.1 pandas==2.2.2 matplotlib==3.9.0 scikit-learn==1.5.0 torch==2.2.0 numpy==1.23.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries\n",
    "\n",
    "The following code imports the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import accumulate\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe, Vectors\n",
    "from torchtext.datasets import IMDB\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "import pickle\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import io\n",
    "\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "\n",
    "The following code shows some helper functions to help with plotting, saving, and loading files. These functions are not the main focus of this lab, so you do not have to dwell on these too long. However, do run the cells in this section to define these helper functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(COST,ACC):\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(COST, color=color)\n",
    "    ax1.set_xlabel('epoch', color=color)\n",
    "    ax1.set_ylabel('total loss', color=color)\n",
    "    ax1.tick_params(axis='y', color=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color=color)  # you already handled the x-label with ax1\n",
    "    ax2.plot(ACC, color=color)\n",
    "    ax2.tick_params(axis='y', color=color)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list_to_file(lst, filename):\n",
    "    \"\"\"\n",
    "    Save a list to a file using pickle serialization.\n",
    "\n",
    "    Parameters:\n",
    "        lst (list): The list to be saved.\n",
    "        filename (str): The name of the file to save the list to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(lst, file)\n",
    "\n",
    "def load_list_from_file(filename):\n",
    "    \"\"\"\n",
    "    Load a list from a file using pickle deserialization.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): The name of the file to load the list from.\n",
    "\n",
    "    Returns:\n",
    "        list: The loaded list.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        loaded_list = pickle.load(file)\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional encodings\n",
    "\n",
    "Positional encodings play a pivotal role in transformers and various sequence-to-sequence models, aiding in conveying critical information regarding the positions or sequencing of elements within a given sequence. To illustrate, let's examine the sentences: \"He painted the car red\" and \"He painted the red car.\" Despite their distinct meanings, it's worth noting that the embeddings for these sentences remain identical in the absence of positional encodings. The following class defines positional encodings by inheriting from PyTorch's `Module` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, vocab_size=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(vocab_size, d_model)\n",
    "        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float()\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import IMDB data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads the IMDB data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/35t-FeC-2uN1ozOwPs7wFg.gz')\n",
    "tar = tarfile.open(fileobj=io.BytesIO(urlopened.read()))\n",
    "tempdir = tempfile.TemporaryDirectory()\n",
    "tar.extractall(tempdir.name)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB data set overview\n",
    "\n",
    "The **IMDB data set** contains movie reviews from the Internet Movie Database (IMDB) and is commonly used for binary sentiment classification tasks. It's a popular data set for training and testing models in natural language processing (NLP), particularly in the context of sentiment analysis.\n",
    "\n",
    "### Data set composition\n",
    "\n",
    "- **Reviews**: The data set consists of 50,000 movie reviews, divided evenly into 25,000 training and 25,000 testing samples.\n",
    "- **Sentiment labels**: Each review is labeled as either positive or negative, indicating the sentiment expressed in the review. The data set is balanced, with an equal number of positive and negative reviews in both the training and testing sets.\n",
    "- **Text content**: Reviews are presented as plain text and have been preprocessed to some extent. For example, HTML tags are removed, but the text retains its original punctuation and capitalization.\n",
    "- **Usage**: The data set is commonly used to train models for binary sentiment classification, where the goal is to predict whether a given review is positive or negative based on its text content.\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Sentiment analysis**: The primary application of the IMDB data set is in sentiment analysis, where it serves as a benchmark for various text classification algorithms.\n",
    "- **Natural language processing**: The data set is widely used in NLP research and applications, providing a basis for testing the effectiveness of different models and approaches in understanding human language.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "The data set is small, so it's hard to train a model from scratch.\n",
    "\n",
    "The following class is defined to traverse the IMDB data set. The need to define this class arises from the fact that the IMDB data set is split across a large number of files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True):\n",
    "        \"\"\"\n",
    "        root_dir: The base directory of the IMDB dataset.\n",
    "        train: A boolean flag indicating whether to use training or test data.\n",
    "        \"\"\"\n",
    "        self.root_dir = os.path.join(root_dir, \"train\" if train else \"test\")\n",
    "        self.neg_files = [os.path.join(self.root_dir, \"neg\", f) for f in os.listdir(os.path.join(self.root_dir, \"neg\")) if f.endswith('.txt')]\n",
    "        self.pos_files = [os.path.join(self.root_dir, \"pos\", f) for f in os.listdir(os.path.join(self.root_dir, \"pos\")) if f.endswith('.txt')]\n",
    "        self.files = self.neg_files + self.pos_files\n",
    "        self.labels = [0] * len(self.neg_files) + [1] * len(self.pos_files)\n",
    "        self.pos_inx=len(self.pos_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return label, content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the `IMDBDataset` class previously defined to create iterators for the train and test data sets. In the latter part of the cell, you can return 20 examples from the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'This is by far one of the worst movies i have ever seen, the poor special effects along with the poor acting are just a few of the things wrong with this film. I am fan of the first two major leagues but this one is lame!')\n",
      "(0, 'Gee, what a crappy movie this was! I cannot understand what people find so scary about \"The Grudge\". The director plays one trick (I\\'d have to admit a very good one, that is brought to life very stylized) and then he repeats it for the rest of the movie over and over again. As a consequence I startled a few times in the first quarter of the movie, but once I knew the drill I practically fell asleep as The Grudge grew more and more predictable by the minute. To conclude, I can say that there are a lot better movies in the genre to begin with, that the so-called predecessor \"The Ring\" was way scarier and that buying a ticket for \"The Grudge\" is a waste of money.')\n",
      "(0, \"This movie starts out very VERY slow, but when the action finally gets started, it's a little had to follow. I couldn't understand why some of the events were taking place, and a lot of events happened before they were explained, making them sort of confusing. The only thing it really has going for it is the massive amount of blood/gore it has, although most times the special effects are lacking. Blood looks like red Kool-Aid. Skin tearing sounds like somebody is stepping on a pile of sticks. Again, the story has a sort of amateur feel to it, like the writer didn't take a long time to perfect it. I feel like it could be a much better movie if the effects were done better and more time was taken on the script. I honestly wish I hadn't watched it, not because of the gore, but because I feel that i wasted 90 minutes of my life. If you like extremely gory movies, this is for you, if not, stay away.\")\n",
      "(0, \"Play Mystery Theater 3000 at home with your friends! Rent this movie for the laughs! The acting is poor, the sounds is terrible and the fights are ridiculously unbelievable. I thought the movie was a joke until I looked it up on IMBD. I can't wait to rent the sequel, China O'Brien II.\")\n",
      "(0, \"From the creators of Shrek\\x85\\x85\\x85\\x85.. OK, that grabbed my attention.<br /><br />Well the creators of Shrek also made Madagascar. Madagascar was half as good as Shrek.<br /><br />And now Flushed Away is half as good as Madagascar.<br /><br />That means Flushed Away isn't good. The animation and all that special effects were extremely good but the movie wasn't.<br /><br />The story of this movie was only meant for kids. It's seriously not possible for adults to actually love this flick.<br /><br />But there were many jokes meant for adults. I bet kids dint understand the jokes.<br /><br />Despite that I dint like this flick.<br /><br />I am completely disappointed. 4/10\")\n",
      "(0, '(Only minor spoilers except as noted).<br /><br />I\\'ve enjoyed a lot of Spanish cinema recently; both the actual Spanish cinema of people like Almodovar, and the Latin American cinema of directors like del Toro, whose superb \"Devil\\'s Backbone\", set in Civil War Spain, was the finest horror film of the last decade. It\\'s no surprise, then, that this film is both well-made, well-acted, and manages to sustain that distinctively different Spanish atmosphere. But it\\'s also as nasty and pointless a film as one could hope not to have to see.<br /><br />What actually is the purpose of all this? We have no real idea what caused the creepy central character to embark on his killing spree, despite the fact that large amounts of narrative voice-over are drawn directly from his own narcissistic journal. In a routinely unpleasant opening sequence, set more than a decade earlier, we see the central character killing his girlfriend in a rage of jealousy and control-freakery (\"\\x85if I can\\'t have you nobody can\\x85.\"). Oddly enough, that is perhaps one of the best sequences in the film, but it has no discernible relation to his subsequent killing spree, which appears completely different in both motivation and execution. What happened to him in jail to cause this change? We have no idea, though we do later discover, as an absurd sort of afterthought, that he obtained a law degree while imprisoned.<br /><br />In Britain, in several of our notorious \"serial killer\" or \"sex killer\" cases, the terrible question arises; what about the wife? Did she know, or suspect what was going on? This is a question that this film could have asked, and indeed the wife does begin to emerge as one of the more intriguing characters. But banally, the answer to the question is quite clearly: \"No, she didn\\'t\". Even when a dramatic opportunity like this is presented on a plate, the film still manages to bungle it. All we actually get, sketched perfunctorily out at the end, is her slightly amoral preparedness to cash in on the proceeds after the event. Compare this to the awful revelatory moment in Ten Rillington Place, where Christie\\'s wife says \"you know what I mean\\x85.\" thereby sealing her own fate and allowing us an appalled glimpse into unimaginable chasms of suppressed knowledge and horror.<br /><br />(Major spoiler in this paragraph). In the meantime, we are supposed to believe that the killer himself is a criminal mastermind who comprehensively outwits the police, thereby securing the briefest of incarcerations in a mental hospital before being released so that he can kill again. How exactly did he achieve this? The plot gets extremely sketchy at this point; something to do with deliberately leaving certain clues for the police; but how this all works or why, or how the subsequent court case actually proceeds, remains a mystery.<br /><br />I actually don\\'t believe serial killers are like this. The Silence of the Lambs may be comic book stuff, but \\x96 Lecter aside \\x96 it gets its serial killers right. They are deeply disturbed, deeply dysfunctional, deeply inadequate people; not the creepily charming mastermind presented here (closely related to the equally implausible suave killer of The Last Horror Movie, or indeed even Man Bites Dog, though it appears not to have been noticed that that was a satire).<br /><br />This film has little suspense, and bungles what little intrigue the plot might have generated. It has nothing useful to say about the motivations of serial killers, either generally, or in the specific cultural milieu of Spain. This is nothing more than a poorly plotted excuse to show some pretty misogynistic violence to women. And oddly, what makes that violence even more repulsive is a certain prissy failure of nerve even in how it is presented. The soft core character of what is actually shown just makes it seem even more repellently titillatory. Just one explicit shot, properly timed, would have been infinitely more shocking, and would have rendered all the rest completely unnecessary, freeing up more film time to flesh out the gaping holes in plot and characterisation. Instead we just get endless shots of young women vulnerably spreadeagled on a table in their pretty but slightly revealing underwear. Very, very creepy. I\\'m sorry to be rude; I love horror films, and can tolerate even the most extreme, to the extent even of worrying my partner. But I think anyone who finds this film good, or interesting, even I\\'d find myself edging away from. The purpose of a horror film is to scare you; this is just lascivious.<br /><br />It leaves a very bad taste in the mouth indeed. I have to give this film more than one star just because it\\'s competently executed, but morally it deserves none at all and should never have been made.')\n",
      "(0, 'The various nudity scenes that other reviewers referred to are poorly done and a body double was obviously used. If Ms. Pacula was reluctant to do the scenes herself perhaps she should have turned down the role offer.<br /><br />Otherwise the movie was not any worse than other typical Canadian movies. As other reviewers have pointed out Canadian movies are generally poorly written and lack entertainment value, which is what most movies watchers are hoping to get. Perhaps Canadian movie producers are consciously trying to \"de-commercialize\" their movies but they have forgotten a very important thing - movies by definition are a commercial thing....')\n",
      "(0, 'Labored comedy has I.R.S. agent Tony Randall investigating eccentric farm family in Maryland who have never paid their taxes; Debbie Reynolds is the tomboy farmer\\'s daughter who puts the squeeze on the not-so-disinterested tax-man. Debbie certainly made her share of inferior theatrical sitcoms during this period--and this one\\'s no better or worse than the rest. Picture begins brightly but flags at the halfway point, becoming frantic and witless. Randall isn\\'t a bad match for Reynolds, but the vehicle itself defeats the chemistry. Based on the novel \"The Darling Buds of May\" by H.E. Bates, with a poor sound-mix causing all the actors to sound as if they\\'re stuck in an echo chamber. ** from ****')\n",
      "(0, \"Well, were to start? This is by far one of the worst films I've ever paid good money to see. I won't comment on the story itself, it's a wonderful classic, but here it feels like a soap opera. To start with, the acting, except for Eric Bana, is soap opera quality. I've always been a fan of Brad Pitt, but here every actor on The Bold and the Beautiful puts him to shame. The camera action doesn't help, either. How it lingers on him when he's thinking, it just takes me back to Brooke Forrester's days in the lab! Peter O'Toole has either had a really bad plastic surgery, or he is desperately in need of one. Either way, he looks more like Linda Evans than Linda Evans! And to end my comments, Diane Kruger is a cute girl, but she sure is no Helen of Troy. Peterson should rather have chosen Saffron Burrows for the role, since Elizabeth Taylor would be rather miscast by now.\")\n",
      "(0, \"'SherryBaby' is quite a painful and sordid melodrama set in Jersey, the story of a young mother who is out of jail on probe after a drugs-related conviction and fights to stay clean, to find a place for herself in life and especially to win back the love of her kid daughter who is being taken care by her brother's family. The only reason the film is to be watched is Maggie Gyllenhaal, an actress at the top of her career, who fits very well in the role and carries the whole film on her shoulders. This is not enough however, as the story line is too simplistic and expected, and the emotional emphasis is put on the wrong place - I kept asking myself all over the picture whether I am supposed to be sorry about the ex and maybe future drug addicted mother as the director and script-writer wanted, or about the innocent kid who is in the middle. Even Maggie Gyllenhaal's acting could not convince me that I should not care more about the kid.\")\n",
      "(1, \"I have read with great interest the only available comment made before mine on this movie and I would first like to say that I understand the point of view of the previous user who commented on this movie very well: viewed from an Israeli perspective, I can very well imagine that this movie touches upon very sensitive issues and that the slightest detail can have a great importance for a viewer who is more or less directly concerned by the events depicted in this movie. What I would like to say is that 'Distortion' was shown at a film festival in Geneva in November 2005 (Festival 'Cinéma tout écran') where it won the award of the audience ('Prix du public'in French). For what affects me, I liked the 'nervous camera' work of Mr Bouzaglo, who, in my opinion, portrayed an atmosphere of extreme tension and uneasiness in the movie very well, and I think that most of the swiss viewers appreciated this in the movie. This perspective, however, might seem totally 'alien' to an Israeli viewer, but not so surprising when it comes to swiss viewers, because Switzerland is a country which has NEVER been subject to any terrorist attack. It therefore comes as no surprise that the audience in Geneva judged this film with a much more 'detached' perspective.I would also like to quote what Mr Bouzaglo said when he was interviewed by a Geneva newspaper (I'm translating from French): ''After 50 years of living here and after undergoing all this violence, we may ask ourselves if it is still possible to remain normal.We might sometimes think that it would be easier to commit suicide than to go on living. We are like the characters in my movie,''on the edge of the edge''. This is the reason why the private detective, who is somehow ''voyeur'' is the happiest character in the movie, because he earns a living thanks to the system, he takes advantage of this situation'' This is, in substance, the main thing that I and the swiss public, in my opinion, pointed out in this movie, and that we did not pay attention to some inconsistencies regarding the characters in the movie which the precedent reviewer pointed out with great accuracy and humor. So, to sum up, different country=different perspective, but I think that this is somehow great, because it reassures me for what affects the future of cinema, that is to say that it well never be subject to a 'unique' of 'formatted' way of thinking.\")\n",
      "(1, 'Historical drama and coming of age story involving free people of color in pre civil war New Orleans. Starts off slow but picks up steam once you have learned about the main characters and the real action can begin. This is not just a story about the exploitation of black women, because these were free people. They may not have had all the rights of whites but they certainly had more control over their destinies than their slave ancestors. The young men and women in this story must each make their own choice about how to live their lives, whether to give into the depravity of the system or live with optimism and contribute to their community. I enjoyed all of the characters but my favorites were Christophe, Anna Bella, and Marcel.')\n",
      "(1, \"Comparable to Fight Club, The Matrix, A.I., Sixth Sense, among others. This film approaches the psyche in a way never done before. The first 30 minutes builds a interesting love story between Diaz-Cruise-Cruz. The rest of the movie is, well, confusing, you'll pick more every time you watch it (i've gone to the movies to see it 3 times now)\")\n",
      "(1, \"Here's another film that doesn't really need much of a recommendation. It's a classic comedy, very funny and entertaining and which, of course, ultimately inspired a successful television series which many would say was even better (I enjoy both, personally). <br /><br />For some, it's hard to warm up to Jack Lemmon and Walter Matthau as Felix Unger and Oscar Madison when they were were weaned on the TV show starring Tony Randall and Jack Klugman (or perhaps vice versa). But what we've got there in both cases are four good actors who in real life seemed so much like their film counterparts that they managed to make these characterizations their own. It's Neil Simon's humorous material that's key, and where the laughs really originate from.<br /><br />For those who have somehow never heard of THE ODD COUPLE, it's the story of a neurotic and fussy neat-freak (Lemmon) who is thrown out of a 12-year marriage by his long-suffering wife and takes up residence in the Manhattan apartment of his sloppy and totally irresponsible buddy (Matthau). Pitting these two unlikely roommates together within the same four walls makes for some hugely funny predicaments.\")\n",
      "(1, 'I saw this film when I was a young child on television (thank-you Canadian Broadcasting Corporation) and had nightmares about it for years afterwards.<br /><br />Trnka was one of the mentors for Bratislav Pojar, one of Canada\\'s National Film Board\\'s best animators. Pojar was, in turn a mentor and collaborator for the great Drouin. If you like Trnka you should see \"Night Angel\".<br /><br />The symbolism is obvious, but deftly used. The oppositions of beauty and life (the plant) are placed in opposition with the anonymity of the gloved hand. The poor puppet hero is condemned despite a lack of political agenda.<br /><br />What I most remembered was the feeling of oppression in the decor. The small room where the action takes place is the character\\'s entire world. The invasion by the hand is a complete violation of that world.<br /><br />Beautiful and haunting film. I found a copy of this and other wonderful shorts by Trnka at the public library and showed it to my own kids. A must see.')\n",
      "(1, 'This was one of those films I probably never would have picked off the shelf , but it came on IFC one day and I said - Eric Stolz, William Forsythe...why not? If I\\'d changed the channel, I would have really missed a treasure. <br /><br />The subject is depressing - young author paralyzed in climbing accident convalesces in lower-class rehabilitation center. It would have been so easy and tempting to make this a manipulative tear-jerker. But, that doesn\\'t happen because it was written by Neal Jimenez, after he himself was accidently paralyzed. No Hollywood happiness here. All of the patients in the ward come from wildly different backgrounds, but they share a feeling of helplessness, of being at the mercy of others. Stolz is very good as a \"lone wolf\" type, forced into embarrassing dependence on his girlfriend (Helen Hunt); Wesley Snipes is fine as a former ladies\\' man whose family is falling apart; but William Forsythe takes the cake as a tough guy determined to make someone pay for taking away his independence.<br /><br />See this film.')\n",
      "(1, \"'One-Round' Jack Sander is called that because he's a carnival boxer who fights any man in the audience. If they can last one round, they win a prize--a popular way to draw customers into traveling shows long ago. Jack is in love with the ticket girl, Mabel, though her head is quickly turned when Bob Corby enters the ring to try his chances with Jack. What no one at the fight knows is that Bob is the champ, so he's able to beat Jack--though it takes him some work. As a result, Bob asks Jack to become his sparring partner and give up the carnival circuit. Later, Jack improves so much that he, too, becomes a legitimate boxer. Slowly, he works his way up the rankings until he's nearly ready to take on the Champ.<br /><br />In the meantime, the Champ and Mabel start running around behind Jack's back--even though by now Mabel has married Jack. So, when the final fight occurs between Jack and Bob, it's very personal and Jack is ready to kill him. Is he good enough? Will rise justifiable rage against Bob help or hinder his performance? Tune in and see.<br /><br />This film was directed by Alfred Hitchcock and while today this sort of film seems strange for a director known for mystery-suspense films, back in the 1920s, Hitchcock had no fixed genre which he directed or wrote (he did both for this film). In fact, in many ways this film is more indicative of Hitchcock's silent style, as a somewhat similar plot came up in one of his next silents, THE MANXMAN (also starring Carl Brisson as the wronged husband). So, while this seems a lot like a standard boxing film of the day, it was not a radical departure for this great director--even with its rather formulaic ending.<br /><br />Overall, while a bit predictable and having Ian Hunter playing a boxing champ seems silly, the film works well. While far from a perfect silent, it's well worth seeing and packs a nice punch.\")\n",
      "(1, \"A Brother's Promise is a wonderful family film. This is a biography of Dan Jansen, a champion Olympic speed skater. The movie depicts this athlete's life from a young age through full adulthood. The love and support of the family members is evident throughout. How Dan and the rest of his family handle winning and losing races is a life lesson for all of us. The commitment and determination of Dan's coach and his teammates, shows what it takes to make a real team. How Dan and his family deal with a devastating illness of a loved one is depicted without undo sentiment or sugarcoating. The faith of the family is shown in basic terms and is obviously a major part of their lives. This is a powerful family film which can be meaningful for a person of any age.\")\n",
      "(1, 'There were times when this movie seemed to get a whole lot more complicated than it needed to be, but I guess that\\'s part of it\\'s charm. Detective Philo Vance\\'s powers of observation seem greater than all the Oriental sleuths of the era combined when it comes down to that final evaluation of how the murders were committed. The dropping of the dagger into the Chinese vase was the kicker for me; I mean, couldn\\'t somebody have just dropped it? <br /><br />Vance (William Powell) had a line early in the film about Archer Coe\\'s \\'psychological impossibility\\' to kill himself - I had to think about that for a while. I was left wondering if there\\'s some scientific basis in fact for that concept to be true, not having studied psychology myself. Seems logical, but then there\\'s always the case that doesn\\'t fit the rules.<br /><br />You know, I got a kick out of the agitated coroner (Etienne Girardot), who reminded me of Star Trek\\'s Dr. McCoy the couple of times he stated \"I\\'m a doctor, not a magician\" and \"I\\'m a doctor, not a detective\". I can picture DeForrest Kelley watching the film and saying to himself - \\'I\\'ll have to use that sometime\\'.<br /><br />Once the killer\\'s identity is revealed, it doesn\\'t seem like such a big surprise, but up till then it\\'s really anybody\\'s guess. But Archer and Brisbane Coe aside, the film didn\\'t answer the central question posed by the title, and the murder I was really interested in - who killed Sir Thomas MacDonald\\'s dog Ghillie?')\n",
      "(1, \"'I only wanted to see you laughing in the Purple Rain.' This is an excell film. It should have been re-rated to PG-13. But anyways, Prince's first film and greatest. The follow-up sucked. But I haven't seen for years so here's what I can remember about it. The Kid (Prince) has to juggle with winning over the love of his life, Apollonia (herself), keeping his band together (The Revolution as themselves) and the tension in his family. But his rival band (The Time as themselves) is ruining his life. Like Morris (himself) is trying to steal Apollonia from The Kid. Just like Saturday Night Fever, Flashdance and 8 Mile. Really good. Rent it, laugh and cry and if you luv it, buy it.\")\n"
     ]
    }
   ],
   "source": [
    "root_dir = tempdir.name + '/' + 'imdb_dataset'\n",
    "train_iter = IMDBDataset(root_dir=root_dir, train=True)  # For training data\n",
    "test_iter = IMDBDataset(root_dir=root_dir, train=False)  # For test data\n",
    "\n",
    "start=train_iter.pos_inx\n",
    "for i in range(-10,10):\n",
    "    print(train_iter[start+i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the mapping of numeric labels to positive and negative reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive review'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_label = {0: \" negative review\", 1: \"positive review\"}\n",
    "imdb_label[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks to ensure that there are exactly two classes in the train data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "num_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads a basic English tokenizer and defines a function called ```yield_tokens``` that uses the tokenizer to break down text data yielded by an iterator into tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "def yield_tokens(data_iter):\n",
    "    \"\"\"Yield tokens for each data sample.\"\"\"\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following code loads a pretrained word embedding model called GloVe into a variable called `glove_embedding`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file data.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 29\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     glove_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mGloVe_override\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[64], line 15\u001b[0m, in \u001b[0;36mGloVe_override.__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#name = \"glove.{}/glove.{}.{}d.txt\".format(name, name, str(dim))\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGloVe_override\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchtext/vocab/vectors.py:59\u001b[0m, in \u001b[0;36mVectors.__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munk_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mzero_ \u001b[38;5;28;01mif\u001b[39;00m unk_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m unk_init\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_vectors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchtext/vocab/vectors.py:170\u001b[0m, in \u001b[0;36mVectors.cache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading vectors from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path_pt))\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoi, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_pt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1168\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[0;32m-> 1168\u001b[0m data_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle_file\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file data.pkl: file not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 32\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     glove_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mGloVe_override2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[64], line 26\u001b[0m, in \u001b[0;36mGloVe_override2.__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/glove.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124md.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, name, \u001b[38;5;28mstr\u001b[39m(dim))\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGloVe_override2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchtext/vocab/vectors.py:59\u001b[0m, in \u001b[0;36mVectors.__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munk_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mzero_ \u001b[38;5;28;01mif\u001b[39;00m unk_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m unk_init\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_vectors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchtext/vocab/vectors.py:170\u001b[0m, in \u001b[0;36mVectors.cache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading vectors from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path_pt))\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoi, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_pt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1141\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m   1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute '_utils'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m     glove_embedding \u001b[38;5;241m=\u001b[39m GloVe_override2(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6B\u001b[39m\u001b[38;5;124m\"\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     glove_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mGloVe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchtext/vocab/vectors.py:220\u001b[0m, in \u001b[0;36mGloVe.__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl[name]\n\u001b[1;32m    219\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124md.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, \u001b[38;5;28mstr\u001b[39m(dim))\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGloVe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchtext/vocab/vectors.py:59\u001b[0m, in \u001b[0;36mVectors.__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munk_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mzero_ \u001b[38;5;28;01mif\u001b[39;00m unk_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m unk_init\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_vectors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchtext/vocab/vectors.py:170\u001b[0m, in \u001b[0;36mVectors.cache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading vectors from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path_pt))\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoi, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_pt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1168\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[0;32m-> 1168\u001b[0m data_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle_file\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file data.pkl: file not found"
     ]
    }
   ],
   "source": [
    "# Note that GloVe embeddings are typically downloaded using:\n",
    "#glove_embedding = GloVe(name=\"6B\", dim=100)\n",
    "# However, the GloVe server is frequently down. The code below offers a workaround\n",
    "\n",
    "\n",
    "class GloVe_override(Vectors):\n",
    "    url = {\n",
    "        \"6B\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/tQdezXocAJMBMPfUJx_iUg/glove-6B.zip\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, name=\"6B\", dim=100, **kwargs) -> None:\n",
    "        url = self.url[name]\n",
    "        name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
    "        #name = \"glove.{}/glove.{}.{}d.txt\".format(name, name, str(dim))\n",
    "        super(GloVe_override, self).__init__(name, url=url, **kwargs)\n",
    "\n",
    "class GloVe_override2(Vectors):\n",
    "    url = {\n",
    "        \"6B\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/tQdezXocAJMBMPfUJx_iUg/glove-6B.zip\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, name=\"6B\", dim=100, **kwargs) -> None:\n",
    "        url = self.url[name]\n",
    "        #name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
    "        name = \"glove.{}/glove.{}.{}d.txt\".format(name, name, str(dim))\n",
    "        super(GloVe_override2, self).__init__(name, url=url, **kwargs)\n",
    "\n",
    "try:\n",
    "    glove_embedding = GloVe_override(name=\"6B\", dim=100)\n",
    "except:\n",
    "    try:\n",
    "        glove_embedding = GloVe_override2(name=\"6B\", dim=100)\n",
    "    except:\n",
    "        glove_embedding = GloVe(name=\"6B\", dim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code builds a vocabulary object from a pretrained GloVe word embedding model and sets the default index to the <unk> token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'stoi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GloVe,vocab\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Build vocab from glove_vectors\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m vocab \u001b[38;5;241m=\u001b[39m vocab(\u001b[43mglove_embedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstoi\u001b[49m, \u001b[38;5;241m0\u001b[39m,specials\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m vocab\u001b[38;5;241m.\u001b[39mset_default_index(vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'stoi'"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe,vocab\n",
    "# Build vocab from glove_vectors\n",
    "vocab = vocab(glove_embedding .stoi, 0,specials=('<unk>', '<pad>'))\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the number of words in the vocab:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the ```vocab``` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab(['he'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following converts the data set into map-style data sets and then performs a random split to create separate training and validation data sets. The training data set will contain 95% of the samples in the original training set, while the validation data set will contain the remaining 5%. These data sets can be used for training and evaluating a machine learning model for text classification on the IMDB data set. The final performance of the model will be evaluated on the hold-out test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training and testing iterators to map-style datasets.\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "# Determine the number of samples to be used for training and validation (5% for validation).\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "\n",
    "# Randomly split the training dataset into training and validation datasets using `random_split`.\n",
    "# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that the Skills Network currently does not offer GPU access to learners. As a result, training on the full data set could be time-consuming. To address this, you further reduce the size of the training set. This approach helps you mimic the training process as if a GPU were available. However, if you want to train using the full IMDB data set, you must either comment out or remove the two lines in the following code block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(train_dataset) * 0.05)\n",
    "split_train_, _ = random_split(split_train_, [num_train, len(split_train_) - num_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks to see if a CUDA-compatible GPU is available in the system using PyTorch, a popular deep learning framework. If a GPU is available, it assigns the device variable to \"cuda\" (which stands for CUDA, the parallel computing platform and application programming interface model developed by NVIDIA). If a GPU is not available, it assigns the device variable to \"cpu\" (which means the code will run on the CPU instead).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code prepares the text processing pipeline with the tokenizer and vocabulary. The text pipeline is used to process the raw data strings from the data set iterators.\n",
    "\n",
    "The function **```text_pipeline```** first tokenizes the input text, then **```vocab```** is applied to get the token indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):\n",
    "    return vocab(tokenizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the **`collate_fn`** function is used in conjunction with data loaders to customize the way batches are created from individual samples. The provided code defines a `collate_batch` function in PyTorch, which is used with data loaders to customize batch creation from individual samples. It processes a batch of data, including labels and text sequences. It applies the `text_pipeline` function to preprocess the text. The processed data is then converted into PyTorch tensors and returned as a tuple containing the label tensor, text tensor, and offsets tensor representing the starting positions of each text sequence in the combined tensor. The function also ensures that the returned tensors are moved to the specified device (for example, GPU) for efficient computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _label, _text in batch:\n",
    "\n",
    "        label_list.append(_label)\n",
    "        text_list.append(torch.tensor(text_pipeline(_text), dtype=torch.int64))\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert the data set objects to data loaders by applying the `collate` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see what these data loaders generate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label,seqence=next(iter(valid_dataloader))\n",
    "label,seqence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a class called Net that represents a text classifier based on a PyTorch TransformerEncoder.\n",
    "The constructor takes the following arguments:\n",
    "\n",
    "- `num_class`: The number of classes to classify\n",
    "- `vocab_size`: The size of the vocabulary\n",
    "- `freeze`: Whether to freeze the embedding layer\n",
    "- `nhead`: The number of heads in the transformer encoder\n",
    "- `dim_feedforward`: The dimension of the feedforward layer in the transformer encoder\n",
    "- `num_layers`: The number of transformer encoder layers\n",
    "- `dropout`: The dropout rate\n",
    "- `activation`: The activation function to use in the transformer encoder\n",
    "- `classifier_dropout`: The dropout rate for the classifier\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "- `emb`: An embedding layer that maps each word in the vocabulary to a dense vector representation\n",
    "- `pos_encoder`: A positional encoding layer that adds positional information to the word vectors\n",
    "- `transformer_encoder`: A transformer encoder layer that processes the sequence of word vectors and extracts high-level features\n",
    "- `classifier`: A linear layer that maps the output of the transformer encoder to the desired number of classes\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Text classifier based on a pytorch TransformerEncoder.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "\n",
    "        self,\n",
    "        num_class,vocab_size,\n",
    "        freeze=True,\n",
    "        nhead=2,\n",
    "        dim_feedforward=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.1,\n",
    "        activation=\"relu\",\n",
    "        classifier_dropout=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        #self.emb = embedding=nn.Embedding.from_pretrained(glove_embedding.vectors,freeze=freeze)\n",
    "        self.emb = nn.Embedding.from_pretrained(glove_embedding.vectors,freeze=freeze)\n",
    "        embedding_dim = self.emb.embedding_dim\n",
    "\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(\n",
    "            d_model=embedding_dim,\n",
    "            dropout=dropout,\n",
    "            vocab_size=vocab_size,\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.classifier = nn.Linear(embedding_dim, num_class)\n",
    "        self.d_model = embedding_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can then be trained on labeled data from the IMDB data set with two classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net(num_class=2,vocab_size=vocab_size).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following **`predict`** function takes in a text, a text pipeline, and a model as inputs. It uses a pretrained model passed as a parameter to predict the label of the text for text classification on the IMDB data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, text_pipeline, model):\n",
    "    with torch.no_grad():\n",
    "        text = torch.unsqueeze(torch.tensor(text_pipeline(text)),0).to(device)\n",
    "        model.to(device)\n",
    "        output = model(text)\n",
    "        return imdb_label[output.argmax(1).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"I like sports and stuff\", text_pipeline, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a function to evaluate the model's accuracy on a data set. Here, you define two nearly identical evaluation functions, one that provides a `tqdm` progress bar, and one that does not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model_eval):\n",
    "    model_eval.eval()\n",
    "    total_acc, total_count= 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, text in tqdm(dataloader):\n",
    "            label, text = label.to(device), text.to(device)\n",
    "            output = model_eval(text)\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            total_acc += (predicted == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_no_tqdm(dataloader, model_eval):\n",
    "    model_eval.eval()\n",
    "    total_acc, total_count= 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, text in dataloader:\n",
    "            label, text = label.to(device), text.to(device)\n",
    "            output = model_eval(text)\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            total_acc += (predicted == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code evaluates the performance of your model. Note that this can take approximately 4 minutes on a CPU. **For efficiency, let's not run this cell now, but trust us that the performance of the untrained model is no better than average. If you wish to confirm yourself of this fact, you are free to uncomment this cell**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the current performance of the model is no better than average. This outcome is expected, considering that the model has not undergone any training yet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following coe defines the training function used to train your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, train_dataloader, valid_dataloader,  epochs=1000, save_dir=\"\", file_name=None):\n",
    "    cum_loss_list = []\n",
    "    acc_epoch = []\n",
    "    acc_old = 0\n",
    "    model_path = os.path.join(save_dir, file_name)\n",
    "    acc_dir = os.path.join(save_dir, os.path.splitext(file_name)[0] + \"_acc\")\n",
    "    loss_dir = os.path.join(save_dir, os.path.splitext(file_name)[0] + \"_loss\")\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        model.train()\n",
    "        #print(model)\n",
    "        #for parm in model.parameters():\n",
    "        #    print(parm.requires_grad)\n",
    "        \n",
    "        cum_loss = 0\n",
    "        for idx, (label, text) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            label, text = label.to(device), text.to(device)\n",
    "\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            loss.backward()\n",
    "            #print(loss)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            cum_loss += loss.item()\n",
    "        print(f\"Epoch {epoch}/{epochs} - Loss: {cum_loss}\")\n",
    "\n",
    "        cum_loss_list.append(cum_loss)\n",
    "        accu_val = evaluate_no_tqdm(valid_dataloader,model)\n",
    "        acc_epoch.append(accu_val)\n",
    "\n",
    "        if model_path and accu_val > acc_old:\n",
    "            print(accu_val)\n",
    "            acc_old = accu_val\n",
    "            if save_dir is not None:\n",
    "                pass\n",
    "                #print(\"save model epoch\",epoch)\n",
    "                #torch.save(model.state_dict(), model_path)\n",
    "                #save_list_to_file(lst=acc_epoch, filename=acc_dir)\n",
    "                #save_list_to_file(lst=cum_loss_list, filename=loss_dir)\n",
    "\n",
    "    time_end = time.time()\n",
    "    print(f\"Training time: {time_end - time_start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train IMDB\n",
    "\n",
    "The following code sets the learning rate (LR) to 1, which determines the step size at which the optimizer updates the model's parameters during training. The CrossEntropyLoss criterion is used to calculate the loss between the model's predicted outputs and the ground truth labels. This loss function is commonly employed for multiclass classification tasks.\n",
    "\n",
    "The chosen optimizer is Stochastic Gradient Descent (SGD), which optimizes the model's parameters based on the computed gradients with respect to the loss function. The SGD optimizer uses the specified learning rate to control the size of the weight updates.\n",
    "\n",
    "Additionally, a learning rate scheduler is defined using StepLR. This scheduler adjusts the learning rate during training, reducing it by a factor (gamma) of 0.1 after every epoch (step) to improve convergence and fine-tune the model's performance. These components together form the essential setup for training a neural network using the specified learning rate, loss criterion, optimizer, and learning rate scheduler.\n",
    "\n",
    "For the sake of time efficiency, **the following lines are commented out and the model is not actually trained**. If you would like to get a glimpse of what training would look like, uncomment the following code block to train the model for 2 epochs. If you were to train this model in a real-world scenario, you would likely increase the number of epochs to a larger figure, such as 100 or more. Given the reduced training set defined earlier, it takes approximately 2 minutes to complete 2 epochs of training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LR=1\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "save_dir = \"\"\n",
    "file_name = \"model_IMDB dataset small2.pth\"\n",
    "train_model(model=model, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            train_dataloader=train_dataloader, \n",
    "            valid_dataloader=valid_dataloader, \n",
    "            epochs=2, \n",
    "            save_dir=save_dir, \n",
    "            file_name=file_name\n",
    "           )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a model that has been pretrained using the same method but on the full data set and with 100 epochs.\n",
    "\n",
    "The following code plots the cost and validation data accuracy for each epoch of the pretrained model up to and including the epoch that yielded the highest accuracy. As you can see, the pretrained model achieved an accuracy of over 85% on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/sybqacL5p1qeEO8d4xRZNg/model-IMDB%20dataset%20small2-acc')\n",
    "loss_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/eOt6woGoaOB565T0RLH5WA/model-IMDB%20dataset%20small2-loss')\n",
    "acc_epoch = pickle.load(acc_urlopened)\n",
    "cum_loss_list = pickle.load(loss_urlopened)\n",
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads your pretrained model and evaluates its performance on the test set. **For efficiency, let's not run the evaluation because it can take approximately 4 minutes to run. Instead, report the result underneath the cell. If you would like to confirm the result for yourself, you are free to uncomment the last line in the following code block.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/q66IH6a7lglkZ4haM6hB1w/model-IMDB%20dataset%20small2.pth')\n",
    "model_ = Net(vocab_size=vocab_size, num_class=2).to(device)\n",
    "model_.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))\n",
    "#evaluate(test_dataloader, model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the pretrained model achieved an accuracy of approximately 83% on the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune a model pretrained on the AG News data set\n",
    "\n",
    "Rather than training a model on the IMDB data set as you did earlier, you can fine-tune a model that has been pretrained on the AG News data set, which is a collection of news articles. The goal of the AG News data set is to categorize news articles into one of four categories: Sports, Business, Sci/tech, or World. You’ll start training a model from scratch on the AG News data set. To save time, you can do this in just one cell. Also, for efficiency, ** comment out the training bit**. If you want to train the model for 2 epochs on a smaller data set to demonstrate what the training process would look like, uncomment the part that says `### Uncomment to Train ###` before running the cell. Training for 2 epochs on the reduced data set can take approximately 3 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_ag_news = AG_NEWS(split=\"train\")\n",
    "\n",
    "num_class_ag_news = len(set([label for (label, text) in train_iter_ag_news ]))\n",
    "num_class_ag_news\n",
    "\n",
    "# Split the dataset into training and testing iterators.\n",
    "train_iter_ag_news, test_iter_ag_news = AG_NEWS()\n",
    "\n",
    "# Convert the training and testing iterators to map-style datasets.\n",
    "train_dataset_ag_news = to_map_style_dataset(train_iter_ag_news)\n",
    "test_dataset_ag_news = to_map_style_dataset(test_iter_ag_news)\n",
    "\n",
    "# Determine the number of samples to be used for training and validation (5% for validation).\n",
    "num_train_ag_news = int(len(train_dataset_ag_news) * 0.95)\n",
    "\n",
    "# Randomly split the training dataset into training and validation datasets using `random_split`.\n",
    "# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n",
    "split_train_ag_news_, split_valid_ag_news_ = random_split(train_dataset_ag_news, [num_train_ag_news, len(train_dataset_ag_news) - num_train_ag_news])\n",
    "\n",
    "# Make the training set smaller to allow it to run fast as an example.\n",
    "# IF YOU WANT TO TRAIN ON THE AG_NEWS DATASET, COMMENT OUT THE 2 LINEs BELOW.\n",
    "# HOWEVER, NOTE THAT TRAINING WILL TAKE A LONG TIME\n",
    "num_train_ag_news = int(len(train_dataset_ag_news) * 0.05)\n",
    "split_train_ag_news_, _ = random_split(split_train_ag_news_, [num_train_ag_news, len(split_train_ag_news_) - num_train_ag_news])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "def label_pipeline(x):\n",
    "   return int(x) - 1\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch_ag_news(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        text_list.append(torch.tensor(text_pipeline(_text), dtype=torch.int64))\n",
    "\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "\n",
    "\n",
    "    return label_list.to(device), text_list.to(device)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader_ag_news = DataLoader(\n",
    "    split_train_ag_news_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch_ag_news\n",
    ")\n",
    "valid_dataloader_ag_news = DataLoader(\n",
    "    split_valid_ag_news_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch_ag_news\n",
    ")\n",
    "test_dataloader_ag_news = DataLoader(\n",
    "    test_dataset_ag_news, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch_ag_news\n",
    ")\n",
    "\n",
    "\n",
    "model_ag_news = Net(num_class=4,vocab_size=vocab_size).to(device)\n",
    "model_ag_news.to(device)\n",
    "\n",
    "'''\n",
    "### Uncomment to Train ###\n",
    "LR=1\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_ag_news.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "save_dir = \"\"\n",
    "file_name = \"model_AG News small1.pth\"\n",
    "train_model(model=model_ag_news, optimizer=optimizer, criterion=criterion, train_dataloader=train_dataloader_ag_news, valid_dataloader=valid_dataloader_ag_news,  epochs=2, save_dir=save_dir, file_name=file_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a model that has been pretrained using the same method but on the full AG News data set for 100 epochs.\n",
    "\n",
    "The following code plots the cost and validation data accuracy for each epoch of the pretrained model up to and including the epoch that yielded the highest accuracy. As you can see, the pretrained model achieved a very high accuracy of over 90% on the AG News validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/bQk8mJu3Uct3I4JEsEtRnw/model-AG%20News%20small1-acc')\n",
    "loss_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/KNQkqJWWwY_XfbFBRFhZNA/model-AG%20News%20small1-loss')\n",
    "acc_epoch = pickle.load(acc_urlopened)\n",
    "cum_loss_list = pickle.load(loss_urlopened)\n",
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads the pretrained model and evaluates its performance on the AG News test set. **For efficiency, let's not run the evaluation because it can take a few minutes. Instead, claim that the pretrained model works well on the AG News dataset. If you would like to confirm the result for yourself, feel free to uncomment the last line in the following code block.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/9c3Dh2O_jsYBShBuchUNlg/model-AG%20News%20small1.pth')\n",
    "model_ag_news_ = Net(vocab_size=vocab_size, num_class=4).to(device)\n",
    "model_ag_news_.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))\n",
    "#evaluate(test_dataloader_ag_news, model_ag_news_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the pretrained model worked extremely well on the AG News data set. However, can this model be fine-tuned to perform well on the IMDB data set as well? Let's find out! You can begin by loading the pretrained AG News model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/9c3Dh2O_jsYBShBuchUNlg/model-AG%20News%20small1.pth')\n",
    "model_fine1 = Net(vocab_size=vocab_size, num_class=4).to(device)\n",
    "model_fine1.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB dataset is a binary classification task with only two classes (positive and negative reviews). Therefore, the output layer of the AG NEWS model should be adjusted to have just two output neurons to reflect the binary nature of the IMDB dataset. This adjustment is essential for the model to accurately learn and predict the sentiment of movie reviews in the IMDB dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine1.classifier\n",
    "in_features = model_fine1.classifier.in_features\n",
    "print(\"Original final layer:\", model_fine1.classifier)\n",
    "print(\"Input dimention  final layer:\", in_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the final layer into a two-class problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine1.classifier = nn.Linear(in_features, 2)\n",
    "model_fine1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows the layers that are frozen (`requires_grad == False`) and unfrozen (`requires_grad == True`) in the model. The unfrozen layers will have their weights updated during fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_fine1.named_parameters():\n",
    "    print(f\"{name} requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block simulates fine-tuning on the shortened training set for just 2 epochs. **For the sake of time efficiency, this code block has been commented out**. If you want to see what training looks like, uncomment the following code block, but remember that this code could take approximately 2 minutes to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LR=1\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_fine1.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "save_dir = \"\"\n",
    "file_name = \"model_fine1.pth\"\n",
    "train_model(model=model_fine1, optimizer=optimizer, criterion=criterion, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader,  epochs=2,  save_dir=save_dir ,file_name=file_name )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows the progress of full fine-tuning of the entire IMDB training set for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/3LEJw8BRgJJFGqlLxaETxA/model-fine1-acc')\n",
    "loss_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/-CT1h97vjv0TolY82Nw29g/model-fine1-loss')\n",
    "acc_epoch = pickle.load(acc_urlopened)\n",
    "cum_loss_list = pickle.load(loss_urlopened)\n",
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line loads a prefine-tuned model that was trained for 100 epochs on the full IMDB training set and evaluates its performance on the IMDB test set. **For the sake of efficiency, let's not run the evaluation because it can take a few minutes to run. Instead, report the result underneath the cell. If you would like to confirm the result for yourself, feel free to uncomment the last line in the code block.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/e0WOHKh5dnrbC2lGhpsMMw/model-fine1.pth')\n",
    "model_fine1_ = Net(vocab_size=vocab_size, num_class=2).to(device)\n",
    "model_fine1_.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))\n",
    "#evaluate(test_dataloader, model_fine1_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model demonstrated notable improvement, exhibiting a remarkable achievement with an accuracy of 86% on the test data. This is higher than the 83% achieved by the model trained from scratch on the IMDB dataset. Although the training process was time-intensive (The fine-tuning was as time-intensive as training the model from scratch), the enhanced performance underscores the fine-tuned model's effectiveness and superiority over the model trained from scratch. Much of the computational effort was devoted to updating the transformer layers. To expedite the training process, one viable strategy is to focus on training the final layer only, which can significantly reduce the computational load but might compromise the model's accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the final layer only\n",
    "\n",
    "Fine-tuning the final output layer of a neural network is similar to fine-tuning the whole model. You can begin by loading the pretrained model that you would like to fine-tune. In this case, it is the same model pretrained on the AG News data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/9c3Dh2O_jsYBShBuchUNlg/model-AG%20News%20small1.pth')\n",
    "model_fine2 = Net(vocab_size=vocab_size, num_class=4).to(device)\n",
    "model_fine2.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the key difference. You iterate through all of the parameters in the `model_fine2` model and set the `requires_grad` attribute of each parameter to `False`. This effectively freezes all of the layers in the model, meaning that their weights are to be updated during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in the model\n",
    "for param in model_fine2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the final layer to reflect the fact that you are solving a two-class problem. Note that the new layer will be unfrozen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=model_fine2.classifier.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine2.classifier = nn.Linear(dim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine2.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block simulates fine-tuning on the shortened training set for just 2 epochs. **For the sake of time efficiency, this code block has been commented out**. The following code should take a shorter amount of time to train than the full fine-tuning conducted previously because only the final layer is unfrozen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LR=1\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_fine2.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "save_dir = \"\"\n",
    "file_name = \"model_fine2.pth\"\n",
    "train_model(model=model_fine2, optimizer=optimizer, criterion=criterion, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader,  epochs=2,  save_dir=save_dir ,file_name=file_name )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, you will not use the model that you just fine-tuned, but instead inspect the final layer fine-tuning process of a model fine-tuned on the full IMDB training set for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/UdR3ApQnxSeV2mrA0CbiLg/model-fine2-acc')\n",
    "loss_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/rWGDIF-uL2dEngWcIo9teQ/model-fine2-loss')\n",
    "acc_epoch = pickle.load(acc_urlopened)\n",
    "cum_loss_list = pickle.load(loss_urlopened)\n",
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line loads the pretrained model and evaluates its performance on the test set. **For efficiency, let's not run the evaluation because it can take a few minutes to run. Instead, report the result underneath the cell. If you would like to confirm the result for yourself, feel free to uncomment the last line in the following code block.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/B-1H6lpDg-A0zRwpB6Ek2g/model-fine2.pth')\n",
    "model_fine2_ = Net(vocab_size=vocab_size, num_class=2).to(device)\n",
    "model_fine2_.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))\n",
    "#evaluate(test_dataloader, model_fine2_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code indicates that although fine-tuning the final layer takes a significantly smaller amount of time than fine-tuning the whole model, the performance of the model with just the last layer unfrozen is significantly worse (64% accuracy) than the fine-tuned model with all layers unfrozen (86% accuracy).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapters\n",
    "FeatureAdapter is a neural network module that introduces a low-dimensional bottleneck in a transformer architecture to allow fine-tuning with fewer parameters. It compresses the original high-dimensional embeddings into a lower dimension, applies a non-linear transformation, and then expands it back to the original dimension. This process is followed by a residual\n",
    "connection that adds the transformed output back to the original input to preserve information and\n",
    "promote gradient flow.\n",
    "\n",
    "## Benefits of using adapters in neural networks\n",
    "\n",
    "- **Efficient fine-tuning**: Adapters allow for targeted updates to specific parts of the model, reducing the need to retrain large sections of the network.\n",
    "\n",
    "- **Parameter efficiency**: By adding only a few parameters, adapters make it feasible to modify large models without substantial computational overhead.\n",
    "\n",
    "- **Preservation of pretrained features**: Adapters enable the modification of a model while retaining the valuable features learned during extensive pretraining.\n",
    "\n",
    "- **Modularity and flexibility**: They enhance the modularity of models, allowing easy adaptation to various tasks without altering core architecture.\n",
    "\n",
    "- **Task-specific adaptation**: Adapters can be tailored to improve performance on particular tasks, optimizing the model’s effectiveness.\n",
    "\n",
    "- **Transfer learning and domain adaptation**: They facilitate the adaptation of models to new domains, bridging gaps between different data distributions.\n",
    "\n",
    "- **Continual learning**: Adapters support the model's ability to learn new information continuously without forgetting previous knowledge.\n",
    "\n",
    "- **Reduced risk of overfitting**: With fewer trainable parameters, adapters help prevent overfitting, especially on smaller data sets.\n",
    "\n",
    "The following code shows an adapter model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureAdapter(nn.Module):\n",
    "    \"\"\"\n",
    "    Attributes:\n",
    "        size (int): The bottleneck dimension to which the embeddings are temporarily reduced.\n",
    "        model_dim (int): The original dimension of the embeddings or features in the transformer model.\n",
    "    \"\"\"\n",
    "    def __init__(self, bottleneck_size=50, model_dim=100):\n",
    "        super().__init__()\n",
    "        self.bottleneck_transform = nn.Sequential(\n",
    "            nn.Linear(model_dim, bottleneck_size),  # Down-project to a smaller dimension\n",
    "            nn.ReLU(),                             # Apply non-linearity\n",
    "            nn.Linear(bottleneck_size, model_dim)  # Up-project back to the original dimension\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the FeatureAdapter. Applies the bottleneck transformation to the input\n",
    "        tensor and adds a skip connection.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor with shape (batch_size, seq_length, model_dim).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after applying the adapter transformation and skip connection,\n",
    "                    maintaining the original input shape.\n",
    "        \"\"\"\n",
    "        transformed_features = self.bottleneck_transform(x)  # Transform features through the bottleneck\n",
    "        output_with_residual = transformed_features + x      # Add the residual connection\n",
    "        return output_with_residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adapted class wraps this adapter functionality around any specified linear layer, enhancing its output with the non-linearity of a ReLU activation function. This setup is particularly useful for experimenting with subtle architectural modifications in deep learning models, facilitating fine-tuning and potentially improving model performance on complex tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adapted(nn.Module):\n",
    "    def __init__(self, linear,bottleneck_size=None):\n",
    "        super(Adapted, self).__init__()\n",
    "        self.linear = linear\n",
    "        model_dim = linear.out_features\n",
    "        if bottleneck_size is None:\n",
    "          bottleneck_size = model_dim//2   # Define default bottleneck size as half the model_dim\n",
    "\n",
    "        # Initialize FeatureAdapter with calculated bottleneck_size and model_dim\n",
    "        self.adaptor = FeatureAdapter(bottleneck_size=bottleneck_size, model_dim=model_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First, the input x is passed through the linear layer\n",
    "        x=self.linear(x)\n",
    "        # Then it's adapted using FeatureAdapter\n",
    "        x= self.adaptor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You load the pretrained transformer model that was trained on the AG News dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/9c3Dh2O_jsYBShBuchUNlg/model-AG%20News%20small1.pth')\n",
    "model_adapters = Net(vocab_size=vocab_size, num_class=4).to(device)\n",
    "model_adapters.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, freeze the parameters of a model named model_adapters to prevent them from being updated during training. Then, retrieve the number of input features for the classifier, and replace the classifier with a new linear layer that outputs to two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_adapters.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "dim= model_adapters.classifier.in_features\n",
    "model_adapters.classifier = nn.Linear(dim, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore how to apply the adapted object to a linear layer to obtain the first output. You can obtain the unadapted linear layer for the first output by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_example_layer=model_adapters.transformer_encoder.layers[0].linear1\n",
    "print(my_example_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, you copy the linear layer and add an adapter layer to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_adapeted_layer=Adapted(my_example_layer)\n",
    "print(my_adapeted_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the adapted layer and show that the new layers have their requires_grad attribute set to True, indicating that these layers will be updated during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parm in my_adapeted_layer.parameters():\n",
    "    print(parm.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set a layer in the model to the adapter layer, as shown in the following code in the commented-out line. However, because there are many layers, a more systematic approach would be to traverse the model and replace specific layers with the adapter layer. Note that you should set the bottleneck size to 24, ensuring that there are fewer parameters to train than during a full fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt a specific layer\n",
    "#model_adapters.transformer_encoder.layers[0].linear1=Adapted(my_example_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of layers\n",
    "N_layers=len(model_adapters.transformer_encoder.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse model and adapt\n",
    "for n in range(N_layers):\n",
    "  encoder=model_adapters.transformer_encoder.layers[n]\n",
    "  if encoder.linear1:\n",
    "    print(\" before linear1\")\n",
    "    print(encoder.linear1)\n",
    "    model_adapters.transformer_encoder.layers[n].linear1=Adapted(encoder.linear1, bottleneck_size=24)\n",
    "    print(\" after  linear1\")\n",
    "    print(model_adapters.transformer_encoder.layers[n].linear1)\n",
    "\n",
    "  if encoder.linear2:\n",
    "    print(\" before linear2\")\n",
    "    print(model_adapters.transformer_encoder.layers[n].linear2)\n",
    "    model_adapters.transformer_encoder.layers[n].linear2=Adapted(encoder.linear2, bottleneck_size=24)\n",
    "    print(\" after linear2\")\n",
    "    print(model_adapters.transformer_encoder.layers[n].linear2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code sends the model to the device.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send model to device\n",
    "model_adapters.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following code simulates training of the adapted model by training on a shortend IMDB train set for 2 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=1\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_adapters.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "save_dir = \"\"\n",
    "file_name = \"model_adapters.pth\"\n",
    "train_model(model=model_adapters, optimizer=optimizer, criterion=criterion, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader,  epochs=2,  save_dir=save_dir ,file_name=file_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, you will not use the model you just trained. Instead, you will track the training of an adapted model fine-tuned on the full IMDB dataset for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/D49zrrMPWO_ktwQo7PSHIQ/model-adapters-acc')\n",
    "loss_urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/RXWlmyaco695RiaoU7QsnA/model-adapters-loss')\n",
    "acc_epoch = pickle.load(acc_urlopened)\n",
    "cum_loss_list = pickle.load(loss_urlopened)\n",
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads the adapted model fine-tuned for 100 epochs on the full IMDB train set and evaluates its performance on the IMDB test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adapters_ = Net(vocab_size=vocab_size, num_class=2).to(device)\n",
    "for n in range(N_layers):\n",
    "  encoder=model_adapters_.transformer_encoder.layers[n]\n",
    "  if encoder.linear1:\n",
    "    print(\" before linear1\")\n",
    "    print(encoder.linear1)\n",
    "    model_adapters_.transformer_encoder.layers[n].linear1=Adapted(encoder.linear1, bottleneck_size=24)\n",
    "    print(\" after  linear1\")\n",
    "    print(model_adapters_.transformer_encoder.layers[n].linear1)\n",
    "\n",
    "  if encoder.linear2:\n",
    "    print(\" before linear2\")\n",
    "    print(model_adapters_.transformer_encoder.layers[n].linear2)\n",
    "    model_adapters_.transformer_encoder.layers[n].linear2=Adapted(encoder.linear2, bottleneck_size=24)\n",
    "    print(\" after linear2\")\n",
    "    print(model_adapters_.transformer_encoder.layers[n].linear2)\n",
    "\n",
    "model_adapters_.to(device)\n",
    "for param in model_adapters_.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PGhd5G_NVrWNH-_jdjwNlw/model-adapters.pth')\n",
    "model_adapters_.load_state_dict(torch.load(io.BytesIO(urlopened.read()), map_location=device))\n",
    "evaluate(test_dataloader, model_adapters_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the performance of the fine-tuned adapted model is nearly identical to the fully fine-tuned model, with both models achieving a roughly 86% accuracy. This is an especially surprising result because a significantly smaller number of weights were updated for the adapted model than the fully fine-tuned model. Note that only the adapter layers with a bottleneck size of 24 and the final classifier layer are unfrozen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that adapters can be used for parameter efficient fine-tuning (PEFT) and that the performance of a model fine-tuned using adapters can be almost as good as a fully fine-tuned model with all of the layers unfrozen!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Adapt linear layers in a different network\n",
    "\n",
    "The following code defines a neural network called `NeuralNetwork`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "exercise_model = NeuralNetwork()\n",
    "\n",
    "exercise_model.to(device)\n",
    "for param in exercise_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(exercise_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NeuralNetwork` is a neural network that uses the `Sequential` container from PyTorch. Adapt the first two linear layers in the `Sequential` container by using the bottleneck adapter with a bottleneck size of 30. Also, change the last linear layer to a layer that has 5 outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPLACE THIS YOUR ANSWER ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "exercise_model.linear_relu_stack[0] = Adapted(exercise_model.linear_relu_stack[0], bottleneck_size=30)\n",
    "exercise_model.linear_relu_stack[2] = Adapted(exercise_model.linear_relu_stack[2], bottleneck_size=30)\n",
    "exercise_model.linear_relu_stack[4] = nn.Linear(512, 5)\n",
    "print(exercise_model)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo)\n",
    "\n",
    "Joseph has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wojciech \"Victor\" Fulmyk](https://www.linkedin.com/in/wfulmyk) \n",
    "\n",
    "Wojciech \"Victor\" Fulmyk is a Data Scientist at IBM, and a PhD Candidate in economics at the University of Calgary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ashutosh Sagar](https://www.linkedin.com/in/ashutoshsagar/) is completing his MS in CS from Dalhousie University. He has previous experience working with Natural Language Processing and as a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "[TEXT CLASSIFICATION WITH THE TORCHTEXT LIBRARY](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)\n",
    "\n",
    "[Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/pdf/1902.00751.pdf)\n",
    "\n",
    "[Simple, Scalable Adaptation for Neural Machine Translation](https://arxiv.org/pdf/1909.08478)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "76d39c215db0c382687ee9cbd1add55a12e9d224c61198bd34619b63d8828b90"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
